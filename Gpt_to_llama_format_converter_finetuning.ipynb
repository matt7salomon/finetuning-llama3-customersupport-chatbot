{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8eef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def convert_gpt3_to_llama2(gpt3_jsonl_path, llama2_output_path, prompt_completion_separator=\"\\n\"):\n",
    "#     \"\"\"\n",
    "#     Converts a GPT-3 fine-tuning dataset in JSONL format to a LLaMA 2 fine-tuning format.\n",
    "    \n",
    "#     Args:\n",
    "#     - gpt3_jsonl_path (str): Path to the GPT-3 JSONL fine-tuning dataset.\n",
    "#     - llama2_output_path (str): Path to save the converted LLaMA 2 dataset.\n",
    "#     - prompt_completion_separator (str): Separator to place between prompt and completion (default: newline).\n",
    "    \n",
    "#     The output will be a text file where each line contains the prompt followed by the completion.\n",
    "#     \"\"\"\n",
    "#     with open(gpt3_jsonl_path, 'r') as gpt3_file, open(llama2_output_path, 'w') as llama2_file:\n",
    "#         for line in gpt3_file:\n",
    "#             # Parse each line (which should be a JSON object)\n",
    "#             data = json.loads(line.strip())\n",
    "#             print(data)\n",
    "            \n",
    "#             # Extract the prompt and completion\n",
    "#             prompt = data.get(\"prompt\", \"\").strip()\n",
    "#             completion = data.get(\"completion\", \"\").strip()\n",
    "\n",
    "#             # Combine the prompt and completion\n",
    "#             combined_text = prompt + prompt_completion_separator + completion\n",
    "\n",
    "#             # Write to LLaMA 2 output format (plain text)\n",
    "#             llama2_file.write(combined_text + \"\\n\\n\")\n",
    "#             #print(combined_text)\n",
    "\n",
    "#     print(f\"Conversion complete! LLaMA 2 dataset saved at {llama2_output_path}\")\n",
    "\n",
    "# # Example usage:\n",
    "# gpt3_jsonl_path = \"./data/FAQ_data_cleaned_converted.jsonl\"  # Input GPT-3 dataset in JSONL format\n",
    "# llama2_output_path = \"llama2_fine_tuning_dataset.txt\"  # Output LLaMA 2 dataset\n",
    "\n",
    "# convert_gpt3_to_llama2(gpt3_jsonl_path, llama2_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f172e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def convert_jsonl_to_llama2_format(input_jsonl_path, output_path):\n",
    "#     \"\"\"\n",
    "#     Converts JSONL formatted file with messages to a LLaMA-style format where user input and assistant responses are\n",
    "#     enclosed in <s>[INST]...[/INST]</s> tags.\n",
    "    \n",
    "#     Args:\n",
    "#         input_jsonl_path (str): Path to the input JSONL file.\n",
    "#         output_path (str): Path to the output text file in LLaMA format.\n",
    "#     \"\"\"\n",
    "#     with open(input_jsonl_path, 'r') as jsonl_file, open(output_path, 'w') as output_file:\n",
    "#         for line in jsonl_file:\n",
    "#             # Parse the JSON object in each line\n",
    "#             data = json.loads(line.strip())\n",
    "            \n",
    "#             # Extract the messages list\n",
    "#             messages = data.get('messages', [])\n",
    "            \n",
    "#             # Initialize an empty string to store the converted text\n",
    "#             converted_text = \"\"\n",
    "            \n",
    "#             # Iterate over the messages\n",
    "#             for message in messages:\n",
    "#                 role = message.get('role')\n",
    "#                 content = message.get('content', \"\").strip()\n",
    "\n",
    "#                 if role == 'user':\n",
    "#                     # Start a new instruction block for the user message\n",
    "#                     converted_text += f\"<s>[INST] {content} [/INST] \"\n",
    "#                 elif role == 'assistant':\n",
    "#                     # Append the assistant's response\n",
    "#                     converted_text += f\"{content} </s>\"\n",
    "            \n",
    "#             # Write the converted message to the output file\n",
    "#             output_file.write(converted_text + \"\\n\")\n",
    "\n",
    "#     print(f\"Conversion complete! Output saved to {output_path}\")\n",
    "\n",
    "# # Example usage\n",
    "# input_jsonl_path = \"./data/FAQ_data_cleaned_converted.jsonl\"  # Replace with your actual JSONL file\n",
    "# output_path = \"llama2_finetuning_dataset.txt\"  # Output path for the LLaMA 2 formatted data\n",
    "\n",
    "# convert_jsonl_to_llama2_format(input_jsonl_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834aaaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Output saved to ./data/llama2_finetuning_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_jsonl_to_llama2_format(input_jsonl_path, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Converts JSONL formatted file with messages to a LLaMA-style format and saves it as JSONL.\n",
    "    \n",
    "    Args:\n",
    "        input_jsonl_path (str): Path to the input JSONL file.\n",
    "        output_jsonl_path (str): Path to the output JSONL file in LLaMA 2 format.\n",
    "    \"\"\"\n",
    "    with open(input_jsonl_path, 'r') as jsonl_file, open(output_jsonl_path, 'w') as output_file:\n",
    "        for line in jsonl_file:\n",
    "            # Parse the JSON object in each line\n",
    "            data = json.loads(line.strip())\n",
    "            \n",
    "            # Extract the messages list\n",
    "            messages = data.get('messages', [])\n",
    "            \n",
    "            # Initialize an empty string to store the converted text\n",
    "            converted_text = \"\"\n",
    "\n",
    "            # Iterate over the messages\n",
    "            for message in messages:\n",
    "                role = message.get('role')\n",
    "                content = message.get('content', \"\").strip()\n",
    "\n",
    "                if role == 'user':\n",
    "                    # Start a new instruction block for the user message\n",
    "                    converted_text += f\"<s>[INST] {content} [/INST] \"\n",
    "                elif role == 'assistant':\n",
    "                    # Append the assistant's response\n",
    "                    converted_text += f\"{content} </s>\"\n",
    "            \n",
    "            # Prepare the final JSON object\n",
    "            output_data = {\"formatted_message\": converted_text}\n",
    "            \n",
    "            # Write the output in JSONL format (one JSON object per line)\n",
    "            output_file.write(json.dumps(output_data) + \"\\n\")\n",
    "\n",
    "    print(f\"Conversion complete! Output saved to {output_jsonl_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_jsonl_path = \"./data/FAQ_data_cleaned_converted.jsonl\"  # Replace with your actual JSONL file\n",
    "output_jsonl_path = \"./data/llama2_finetuning_dataset.jsonl\"  # Output path for the LLaMA 2 formatted data\n",
    "\n",
    "convert_jsonl_to_llama2_format(input_jsonl_path, output_jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2780c4a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/llama2_finetuning_dataset.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:1025\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mconvert_dtypes(\n\u001b[1;32m   1028\u001b[0m         infer_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend\n\u001b[1;32m   1029\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:1051\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:1187\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:1403\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1399\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1403\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m     )\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1406\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1407\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1409\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "dataset = pd.read_json(path_or_buf=StringIO('./data/llama2_finetuning_dataset.jsonl'), encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b15b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_jsonl_path, 'r') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        # Parse the JSON object in each line\n",
    "        data = json.loads(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f8fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formatted_message': '<s>[INST] Can I return a product if it was purchased during a promotional event? [/INST] Yes, you can return a product purchased during a promotional event. The refund will be processed based on the amount paid after any applicable discounts. </s>'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5081f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e26a7c69da40939f9769d2de72561e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['formatted_message'],\n",
       "    num_rows: 79\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "Dataset.from_json('./data/llama2_finetuning_dataset.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3943819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_train = load_dataset(dataset_name, split=\"train\", download_mode='force_redownload',verification_mode= \"no_checks\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_python310",
   "language": "python",
   "name": "tf_python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
